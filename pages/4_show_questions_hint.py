# ì¸í„°ë·° ì§„í–‰ì´ ì•„ë‹Œ ì˜ˆìƒ ì§ˆë¬¸ì„ ëª¨ì•„ë³´ê¸° ìœ„í•œ ì„ì‹œ í˜ì´ì§€ ì…ë‹ˆë‹¤.
import os
import sys

import streamlit as st
from langchain.chains.llm import LLMChain
from langchain_openai import ChatOpenAI
from PIL import Image
from streamlit_extras.switch_page_button import switch_page

sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))
from src.generate_question import (create_prompt_feedback,  # ì¶”ê°€
                                   create_prompt_hint)
from src.util import read_prompt_from_txt
from config import DATA_DIR, IMG_PATH, OPENAI_API_KEY

st.session_state["FAV_IMAGE_PATH"] = os.path.join(IMG_PATH, "favicon.png")
st.set_page_config(
    page_title="Hello Jobits",  # ë¸Œë¼ìš°ì €íƒ­ì— ëœ° ì œëª©
    page_icon=Image.open(
        st.session_state.FAV_IMAGE_PATH
    ),  # ë¸Œë¼ìš°ì € íƒ­ì— ëœ° ì•„ì´ì½˜,Image.open ì„ ì´ìš©í•´ íŠ¹ì •ê²½ë¡œ ì´ë¯¸ì§€ ë¡œë“œ
    layout="wide",
    initial_sidebar_state="collapsed",
)
#MODEL_NAME = "gpt-4-0125-preview"
MODEL_NAME = "gpt-3.5-turbo-16k"
NEXT_PAGE = "introduction"

st.session_state.logger.info("start show_questions page")

# ì‚¬ìš©ì ì •ì˜ CSS ìŠ¤íƒ€ì¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
st.markdown(
    """
    <style>
    .stExpander > div:first-child {
        font-weight: bold;
        color: navy;
        border: 1px solid rgba(28, 131, 225, 0.1);
        border-radius: 20px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# questions
st.session_state.questions_showhint = st.session_state.main_question
# ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ìƒì„±

st.title(f"{st.session_state.user_name}ë‹˜ì˜ ê¸°ìˆ ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸ì…ë‹ˆë‹¤.ğŸ¤— ")

st.session_state.prompt_template_fb = read_prompt_from_txt(os.path.join(DATA_DIR, "test/prompt_feedback.txt"))
st.session_state.prompt_template_ht = read_prompt_from_txt(os.path.join(DATA_DIR, "test/prompt_hint.txt"))


# ê° ì§ˆë¬¸ì— ëŒ€í•´ ë²ˆí˜¸ë¥¼ ë§¤ê¸°ê³  í† ê¸€ ìœ„ì ¯ ìƒì„±
for i, question in enumerate(st.session_state.questions_showhint, start=1):

    # ì§ˆë¬¸ì´ ë¹„ì–´ìˆê±°ë‚˜ ê°œí–‰ ë¬¸ìë§Œ í¬í•¨ëœ ê²½ìš° í† ê¸€ì„ ìƒì„±í•˜ì§€ ì•ŠìŒ
    if question.strip():

        # í† ê¸€ ìœ„ì ¯ ìƒì„±
        with st.expander(f"{question}", expanded=False):

            st.caption("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ 500ì ì´ë‚´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”")
            # í…ìŠ¤íŠ¸ ì…ë ¥ ë°•ìŠ¤
            user_answer = st.text_area("ë‹µë³€:", key=f"input_{i}", max_chars=500)

            # ###ë‹µë³€í•˜ê¸° ë²„íŠ¼ ì´í›„ í”¼ë“œë°± @@@@@@@@@@@@@@@@@2
            if st.button("ë‹µë³€í•˜ê¸°", key=f"button_{i}"):

                if not user_answer.strip():
                    st.error("ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                else:
                    # ë²„íŠ¼ í´ë¦­ ì‹œ ì„ì‹œ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
                    temp_message = st.empty()

                    # ì„ì‹œ ë©”ì‹œì§€ì— í…ìŠ¤íŠ¸ í‘œì‹œ
                    temp_message.text("ë‹µë³€ì´ ìƒì„±ë˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")

                    prompt_Feedback = create_prompt_feedback(st.session_state.prompt_template_fb)
                    # proprompt_Feedbackmpt_ ìƒì„±ì™„ë£Œ

                    st.session_state.logger.info("create prompt_Feedback object")

                    ### ëª¨ë¸ ì„¸íŒ… ê·¸ëŒ€ë¡œ
                    llm = ChatOpenAI(temperature=0.0, model_name=MODEL_NAME, openai_api_key=OPENAI_API_KEY)

                    st.session_state.logger.info("create llm object")

                    # í”¼ë“œë°± ì‹œì‘

                    chain_feedback_2 = LLMChain(llm=llm, prompt=prompt_Feedback)

                    st.session_state.logger.info("create chain_feedback_2 object")

                    answer_feedback = chain_feedback_2.run({"question": question, "answer": user_answer})

                    st.session_state.logger.info("answer_feedback complit")

                    # ì„ì‹œ ë©”ì‹œì§€ ì œê±° ë° ìµœì¢… ë‹µë³€ í‘œì‹œ
                    temp_message.empty()
                    st.text(answer_feedback)

            # ###ë‹µë³€í•˜ê¸° ë²„íŠ¼ ì´í›„ í”¼ë“œë°± @@@@@@@@@@@@@@@@@2
            if st.button("íŒíŠ¸ë°›ê¸°", key=f"button_ht_{i}"):

                ### FeedBack Pre-process @@@@@@@@@@@@@@@@@@@@@@@@@@
                st.session_state.logger.info("Start hint precess")
                
                # ë²„íŠ¼ í´ë¦­ ì‹œ ì„ì‹œ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
                temp_message_hint = st.empty()
                    # ì„ì‹œ ë©”ì‹œì§€ì— í…ìŠ¤íŠ¸ í‘œì‹œ
                temp_message_hint.text("íŒíŠ¸ê°€ ìƒì„±ë˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")

                st.session_state.prompt_Hint = create_prompt_hint(st.session_state.prompt_template_ht)
                # proprompt_Feedbackmpt_ ìƒì„±ì™„ë£Œ

                st.session_state.logger.info("create prompt_Hint object")

                ### ëª¨ë¸ ì„¸íŒ…
                llm = ChatOpenAI(temperature=0.0, model_name=MODEL_NAME, openai_api_key=OPENAI_API_KEY)

                st.session_state.logger.info("create llm object")

                # í”¼ë“œë°± ì‹œì‘

                st.session_state.chain_hint_1 = LLMChain(llm=llm, prompt=st.session_state.prompt_Hint)

                st.session_state.logger.info("create chain_hint_1 object")

                st.session_state.answer_hint = st.session_state.chain_hint_1.run({"question": question})

                st.session_state.logger.info("chain_hint_1 complit")

                # ì„ì‹œ ë©”ì‹œì§€ ì œê±° ë° íŒíŠ¸

                st.text(st.session_state.answer_hint)

button_clicked = st.button("ì‹œì‘ í™”ë©´ìœ¼ë¡œ ëŒì•„ê°€ê¸°")

# ë²„íŠ¼ì´ í´ë¦­ë˜ë©´ í•´ë‹¹ í˜ì´ì§€ë¡œ ì „í™˜í•˜ëŠ” ì½”ë“œ
if button_clicked:
    switch_page("user")

st.session_state.question_history = "\n\n".join(st.session_state.questions_showhint)
with open(st.session_state['save_dir'] + "/question_history.txt", "w") as file:
    file.write(st.session_state.question_history)   # ìƒì„±ëœ ì§ˆë¬¸ì„ íŒŒì¼ë¡œ ì €ì¥

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
st.download_button(
    label="ì˜ˆìƒ ì§ˆë¬¸ ë‹¤ìš´ë¡œë“œ",  # ë²„íŠ¼ì— í‘œì‹œë  í…ìŠ¤íŠ¸
    data=st.session_state.question_history,  # ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°
    file_name="questions_history.txt",  # ìƒì„±ë  íŒŒì¼ì˜ ì´ë¦„
    mime="text/plain",  # MIME íƒ€ì… ì§€ì •
)

